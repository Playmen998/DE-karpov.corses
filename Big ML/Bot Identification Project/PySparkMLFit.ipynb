{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c953dcd-7ecc-4f6d-bd5b-8f0c55246c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import argparse\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eefa739-3ab7-46d2-9e8e-a6e8cff81d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'spark_ml_model'\n",
    "LABEL_COL = 'is_bot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "810061c4-ee56-481c-8bfc-2243d7f3234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_conf():\n",
    "    \"\"\"\n",
    "    Создание конфигурации на обучение моделей.\n",
    "\n",
    "    :return: dict - конфигурация экспериментов.\n",
    "    \"\"\"\n",
    "    dt = DecisionTreeClassifier(labelCol=LABEL_COL)\n",
    "    rf = RandomForestClassifier(labelCol=LABEL_COL)\n",
    "    gbt = GBTClassifier(labelCol=LABEL_COL)\n",
    "    model_conf = {\n",
    "        'dt': {'model': dt,\n",
    "               'params': ParamGridBuilder()\n",
    "                   .addGrid(dt.maxDepth, [2, 5, 10])\n",
    "                   .addGrid(dt.maxBins, [10, 20, 40])\n",
    "                   .build(),\n",
    "               'best': None,\n",
    "               'score': None},\n",
    "        'rf': {'model': rf,\n",
    "               'params': ParamGridBuilder()\n",
    "                   .addGrid(rf.maxDepth, [2, 5, 10])\n",
    "                   .addGrid(rf.maxBins, [10, 20, 40])\n",
    "                   .build(),\n",
    "               'best': None,\n",
    "               'score': None},\n",
    "        'gbt': {'model': gbt,\n",
    "                'params': ParamGridBuilder()\n",
    "                    .addGrid(gbt.maxDepth, [2, 5, 10])\n",
    "                    .addGrid(gbt.maxBins, [10, 20, 40])\n",
    "                    .build(),\n",
    "                'best': None,\n",
    "                'score': None}\n",
    "    }\n",
    "    return model_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b979842b-e9ac-4275-8999-c1ef668bd76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(model_key, model_conf):\n",
    "    \"\"\"\n",
    "    Создание пайплаина над выбранной моделью.\n",
    "\n",
    "    :param model_key: ключ типа модели.\n",
    "    :param model_conf: конфигурация моделей эксперимента.\n",
    "    :return: Pipeline\n",
    "    \"\"\"\n",
    "    user_type_indexer = StringIndexer(inputCol='user_type', outputCol=\"user_type_index\")\n",
    "    platform_indexer = StringIndexer(inputCol='platform', outputCol=\"platform_index\")\n",
    "    features = [\"duration\", \"item_info_events\", \"select_item_events\",\n",
    "                \"make_order_events\", \"events_per_min\", \"platform_index\", \"user_type_index\"]\n",
    "    features = VectorAssembler(inputCols=features, outputCol='features')\n",
    "    return Pipeline(stages=[user_type_indexer, platform_indexer, features, model_conf[model_key]['model']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "021f8e6e-251c-4235-b06b-92c54adfac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_cv(model_key, model_conf, evaluator, df_train, df_test):\n",
    "    \"\"\"\n",
    "    Обучение пайплайна модели применяя CrossValidator. Все результаты сохраняются в конфигурации.\n",
    "\n",
    "    :param model_key: ключ типа модели.\n",
    "    :param model_conf: конфигурация моделей эксперимента.\n",
    "    :param evaluator: оценщик качества модели.\n",
    "    :param df_train: датасет для обучения модели.\n",
    "    :param df_test:  датасет для оценки модели.\n",
    "    \"\"\"\n",
    "    cv = CrossValidator(estimator=build_pipeline(model_key, model_conf),\n",
    "                        estimatorParamMaps=model_conf[model_key]['params'],\n",
    "                        evaluator=evaluator,\n",
    "                        numFolds=2,\n",
    "                        parallelism=3)\n",
    "    fitted_models = cv.fit(df_train)\n",
    "    best_model = fitted_models.bestModel\n",
    "    score = evaluator.evaluate(best_model.transform(df_test))\n",
    "    model_conf[model_key]['best'] = best_model\n",
    "    model_conf[model_key]['score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fa23521-bc2a-4265-b054-df177991f486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(spark, data_path, model_path):\n",
    "    \"\"\"\n",
    "    Основной процесс задачи.\n",
    "\n",
    "    :param spark: SparkSession\n",
    "    :param data_path: путь до датасета\n",
    "    :param model_path: путь сохранения обученной модели\n",
    "    \"\"\"\n",
    "    model_conf = get_model_conf()\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"is_bot\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "    df = spark.read.parquet(data_path)\n",
    "    df_bots_train, df_bots_test = df.filter(df.is_bot == 1).randomSplit([0.8, 0.2], 42)\n",
    "    df_users_train, df_users_test = df.filter(df.is_bot == 0).randomSplit([0.8, 0.2], 42)\n",
    "    df_train = df_users_train.union(df_bots_train)\n",
    "    df_test = df_users_test.union(df_bots_test)\n",
    "\n",
    "    for key in model_conf.keys():\n",
    "        fit_cv(key, model_conf, evaluator, df_train, df_test)\n",
    "        log_results(key, model_conf)\n",
    "\n",
    "    key = get_best_key(model_conf)\n",
    "    print(f\"Best model type = {key} with score = {model_conf[key]['score']}\")\n",
    "    best_model = model_conf[key]['best']\n",
    "    best_model.write().overwrite().save(model_path)\n",
    "    print('Best model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35a11d5c-d23e-4886-b69b-7b54b8c2cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_key(model_conf):\n",
    "    \"\"\"\n",
    "    Выбор наилучшей модели согласно оценке.\n",
    "\n",
    "    :param model_conf: конфигурация моделей эксперимента.\n",
    "    :return: ключ лучшей модели из конфигурации.\n",
    "    \"\"\"\n",
    "    md = {k: v['score'] for k, v in model_conf.items()}\n",
    "    return max(md.items(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fb8e162-6e3a-4fde-bc7d-644584e0aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_results(model_key, model_conf):\n",
    "    \"\"\"\n",
    "    Логирование метрик и гиперпараметров модели.\n",
    "\n",
    "    :param model_key: ключ типа модели.\n",
    "    :param model_conf: конфигурация моделей эксперимента.\n",
    "    \"\"\"\n",
    "    j_obj = model_conf[model_key]['best'].stages[-1]._java_obj\n",
    "    print(f'\\nModel type = {model_key}')\n",
    "    print(f\"F1 = {model_conf[model_key]['score']}\")\n",
    "    print(f'maxDepth = {j_obj.getMaxDepth()}')\n",
    "    print(f'maxBins = {j_obj.getMaxBins()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "674c6f45-773a-4540-ae07-569669adf75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data_path, model_path):\n",
    "    spark = _spark_session()\n",
    "    process(spark, data_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7763155b-9bcc-4740-8018-c487943a0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _spark_session():\n",
    "    \"\"\"\n",
    "    Создание SparkSession.\n",
    "\n",
    "    :return: SparkSession\n",
    "    \"\"\"\n",
    "    return SparkSession.builder.appName('PySparkMLFitJob').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f190114-ffe5-4d83-b29e-d603f6aceeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data_path DATA_PATH]\n",
      "                             [--model_path MODEL_PATH]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/karpov/.local/share/jupyter/runtime/kernel-997cfd94-5ac4-4072-b669-b0a9a099b66e.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3259: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_path', type=str, default='session-stat.parquet', help='Please set datasets path.')\n",
    "    parser.add_argument('--model_path', type=str, default=MODEL_PATH, help='Please set model path.')\n",
    "    args = parser.parse_args()\n",
    "    data_path = args.data_path\n",
    "    model_path = args.model_path\n",
    "    main(data_path, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
